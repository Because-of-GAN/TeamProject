{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropLayer(object):\n",
    "\tdef __init__(self, params, blobs):\n",
    "\t\t# initialize our starting and ending (x, y)-coordinates of\n",
    "\t\t# the crop\n",
    "\t\tself.startX = 0\n",
    "\t\tself.startY = 0\n",
    "\t\tself.endX = 0\n",
    "\t\tself.endY = 0\n",
    "\n",
    "\tdef getMemoryShapes(self, inputs):\n",
    "\t\t# the crop layer will receive two inputs -- we need to crop\n",
    "\t\t# the first input blob to match the shape of the second one,\n",
    "\t\t# keeping the batch size and number of channels\n",
    "\t\t(inputShape, targetShape) = (inputs[0], inputs[1])\n",
    "\t\t(batchSize, numChannels) = (inputShape[0], inputShape[1])\n",
    "\t\t(H, W) = (targetShape[2], targetShape[3])\n",
    "\n",
    "\t\t# compute the starting and ending crop coordinates\n",
    "\t\tself.startX = int((inputShape[3] - targetShape[3]) / 2)\n",
    "\t\tself.startY = int((inputShape[2] - targetShape[2]) / 2)\n",
    "\t\tself.endX = self.startX + W\n",
    "\t\tself.endY = self.startY + H\n",
    "\n",
    "\t\t# return the shape of the volume (we'll perform the actual\n",
    "\t\t# crop during the forward pass\n",
    "\t\treturn [[batchSize, numChannels, H, W]]\n",
    "\n",
    "\tdef forward(self, inputs):\n",
    "\t\t# use the derived (x, y)-coordinates to perform the crop\n",
    "\t\treturn [inputs[0][:, :, self.startY:self.endY,\n",
    "\t\t\t\tself.startX:self.endX]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading edge detector...\")\n",
    "protoPath = os.path.sep.join([\"hed_model\",\"deploy.prototxt\"])\n",
    "modelPath = os.path.sep.join([\"hed_model\",\"hed_pretrained_bsds.caffemodel\"])\n",
    "net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "cv2.dnn_registerLayer(\"Crop\", CropLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\Python\\CMP_facades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirlist = os.listdir('C:\\Python\\CMP_facades/img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e,i in enumerate(dirlist):\n",
    "    \n",
    "    image = cv2.imread(os.path.sep.join([\"img\",i]))\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "#     plt.imshow(image, interpolation = 'bicubic')\n",
    "#     plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "#     plt.show()\n",
    "\n",
    "    print(\"[INFO] performing Canny edge detection...\")\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    canny = cv2.Canny(blurred, 30, 150)\n",
    "    \n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(W, H),\n",
    "        mean=(104.00698793, 116.66876762, 122.67891434),\n",
    "        swapRB=False, crop=False)\n",
    "\n",
    "    print(\"[INFO] performing holistically-nested edge detection...\")\n",
    "    net.setInput(blob)\n",
    "    hed = net.forward()\n",
    "    hed = cv2.resize(hed[0, 0], (W, H))\n",
    "    hed = (255 * hed).astype(\"uint8\")\n",
    "    #hed = cv2.Canny(hed, 30, 150)\n",
    "    hed = cv2.bitwise_not(hed)\n",
    "\n",
    "    cv2.imwrite(f'hed{i}', hed)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
